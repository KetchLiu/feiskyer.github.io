---
title: "负载均衡"
type: page
---

负载均衡一般包括几个不同层面，分级多次进行：

* 全球负载均衡系统（GSLB）: 基于地理位置负载均衡DNS
* 用户服务层面负载均衡
* RPC负载均衡

## DNS负载均衡

最简单的是DNS回复中提供多个A纪录或者AAAA纪录，这存在不少的问题：

* 对客户端的行为约束力很弱
* 客户端无法识别最近的地址
* 缓存问题

更好的方案是将权威DNS服务器与GSLB结合起来，DNS回复GSLB的虚拟IP。

引入虚拟IP后，需要注意：

* 平时使用连接跟踪，后端服务增减时使用一致性哈希
* 负载均衡修改链路层目的MAC，而保持全部上层信息不变，后端收到原始的数据包（直接服务器响应DSR），适合小规模网络。当机器需要跨广播域时不可行
* 负载均衡将网络包封装到GRE中，使用后端服务器的地址作为目标地址，后端服务器收到包后先拆除GRE层，再进行常规的处理，这样负载均衡器和后端服务器只需要路由可通即可。封装GRE后增加了包的大小，为了避免拆包，可以在内部使用更大的MTU

## 数据中心内负载均衡

* **识别异常任务并进行流速控制**
* 使用跛脚鸭状态（服务正在监听端口并可以服务请求，但已经明确告诉客户端停止发送请求）无缝停止任务
* 划分子集限制连接池大小，限制某个客户端任务需要连接的后端任务数量
* 负载均衡策略：轮询，最闲轮询，加权轮询等

## 过载保护

* 资源利用率过高时最简单的方法是服务降级，更好的方法是数据中心调度流量，确保每个数据中心都有足够容量来处理请求
* 安装QPS来规划服务容量，或者按照某种静态属性一般是错误的选择，更好的方法是用可用资源来衡量可用容量
* 按重要性配额，全局过载时只针对某些“异常”客户返回错误
* 客户端节流，比如自适应节流算法`requests=K*accepts`，而请求拒绝概率为`max(0, (requests-K*accecpts)/(requests+1))`
* 限制客户端重试次数，限制每客户端重试（比如重试请求比小于10%），并**以指数型延迟重试**
* 处理连接过多：放弃不活跃客户端，传递负载给跨数据中心负载均衡，使用代理处理客户端连接

过载保护一个常见的误区是认为过载后端应该拒绝和停止接受所有请求，然而这其实是与可靠负载均衡是违背的。我们实际上希望客户端可以尽可能继续接受请求，而在有可用资源时才处理。
